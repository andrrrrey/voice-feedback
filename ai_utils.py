import json
import logging
import os
import re
from typing import Tuple

import requests
from dotenv import load_dotenv

load_dotenv()

YANDEX_API_KEY = os.getenv("YANDEX_API_KEY")
YANDEX_FOLDER_ID = os.getenv("YANDEX_FOLDER_ID")
YANDEX_SPEECHKIT_STT_URL = os.getenv(
    "YANDEX_SPEECHKIT_STT_URL",
    "https://stt.api.cloud.yandex.net/speech/v1/stt:recognize",
)
YANDEX_SPEECHKIT_LANG = os.getenv("YANDEX_SPEECHKIT_LANG", "ru-RU")

# üîπ —Ñ–æ—Ä–º–∞—Ç –∞—É–¥–∏–æ –¥–ª—è STT (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî oggopus)
YANDEX_SPEECHKIT_FORMAT = os.getenv("YANDEX_SPEECHKIT_FORMAT", "oggopus")

YANDEX_GPT_URL = os.getenv(
    "YANDEX_GPT_URL",
    "https://llm.api.cloud.yandex.net/foundationModels/v1/completion",
)

# ‚ö†Ô∏è –ú–æ–¥–µ–ª—å –º–æ–∂–Ω–æ —Å–º–µ–Ω–∏—Ç—å –≤ .env, –Ω–∞–ø—Ä–∏–º–µ—Ä –Ω–∞ yandexgpt –∏–ª–∏ yandexgpt-pro
YANDEX_GPT_MODEL = os.getenv("YANDEX_GPT_MODEL", "yandexgpt-lite")

# –ü—Ä–æ–º–ø—Ç—ã –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è

# üîπ –ü—Ä–æ–º–ø—Ç –¥–ª—è –†–ï–†–ê–ô–¢–ê/–ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–ò
NORMALIZATION_PROMPT = os.getenv(
    "YANDEX_GPT_NORMALIZATION_PROMPT",
    "–¢—ã —Ä–µ–¥–∞–∫—Ç–æ—Ä –∫–ª–∏–µ–Ω—Ç—Å–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤.\n"
    "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å –æ—Ç–∑—ã–≤ —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω —Å—Ç–∞–ª —á–∏—â–µ –∏ –ø–æ–Ω—è—Ç–Ω–µ–µ.\n"
    "–ü—Ä–∞–≤–∏–ª–∞:\n"
    "- —Å–æ—Ö—Ä–∞–Ω—è–π —Ñ–∞–∫—Ç—ã –∏ –∏—Å—Ö–æ–¥–Ω–æ–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä–∞ (–Ω–µ–¥–æ–≤–æ–ª—å—Å—Ç–≤–æ/–¥–æ–≤–æ–ª—å—Å—Ç–≤–æ);\n"
    "- —É–±–∏—Ä–∞–π —Å–ª–æ–≤–∞-–ø–∞—Ä–∞–∑–∏—Ç—ã, –ø–æ–≤—Ç–æ—Ä—ã, —É—Å—Ç–Ω—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ —Ç–∏–ø–∞ \"–Ω—É\", \"–∫–∞–∫ –±—ã\";\n"
    "- –∏—Å–ø—Ä–∞–≤–ª—è–π –æ–ø–µ—á–∞—Ç–∫–∏ –∏ –≥—Ä–∞–º–º–∞—Ç–∏–∫—É;\n"
    "- —Ä–∞—Å—Å—Ç–∞–≤–ª—è–π –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è, –¥–µ–ª–∞–π —Ç–µ–∫—Å—Ç —Ü–µ–ª—å–Ω—ã–º –∏ —á–∏—Ç–∞–µ–º—ã–º;\n"
    "- –º–æ–∂–Ω–æ –Ω–µ–º–Ω–æ–≥–æ —É—Ç–æ—á–Ω–∏—Ç—å –∏–ª–∏ —Ä–∞—Å—à–∏—Ä–∏—Ç—å —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏, –Ω–æ –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–æ–≤—ã—Ö —Ñ–∞–∫—Ç–æ–≤.\n"
)

# üîπ –ü—Ä–æ–º–ø—Ç –¥–ª—è –û–¶–ï–ù–ö–ò –¢–û–ù–ê–õ–¨–ù–û–°–¢–ò
SENTIMENT_PROMPT = os.getenv(
    "YANDEX_GPT_SENTIMENT_PROMPT",
    "–¢–µ–ø–µ—Ä—å –æ—Ü–µ–Ω–∏ –æ–±—â–∏–π —Ç–æ–Ω –æ—Ç–∑—ã–≤–∞ –∏ –≤—ã–±–µ—Ä–∏ –æ–¥–Ω—É –º–µ—Ç–∫—É:\n"
    "- positive ‚Äî —è–≤–Ω–∞—è –ø–æ—Ö–≤–∞–ª–∞, —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—ë–Ω–Ω–æ—Å—Ç—å, –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞—Ç—å;\n"
    "- neutral ‚Äî –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ —è–≤–Ω–æ–≥–æ –Ω–µ–¥–æ–≤–æ–ª—å—Å—Ç–≤–∞ –∏–ª–∏ –≤–æ—Å—Ç–æ—Ä–≥–∞;\n"
    "- negative ‚Äî –∂–∞–ª–æ–±—ã, –Ω–µ–¥–æ–≤–æ–ª—å—Å—Ç–≤–æ, –ø–ª–æ—Ö–æ–π —Å–µ—Ä–≤–∏—Å, —Ñ—Ä–∞–∑—ã –≤—Ä–æ–¥–µ "
    "\"–Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é\", \"–±–æ–ª—å—à–µ –Ω–µ –ø—Ä–∏–¥—É\".\n"
    "–í–∞–∂–Ω–æ: –µ—Å–ª–∏ –æ—Ç–∑—ã–≤ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–µ—Ä—å—ë–∑–Ω—ã–µ –∂–∞–ª–æ–±—ã, –º–µ–¥–ª–µ–Ω–Ω–æ–µ –∏–ª–∏ –ø–ª–æ—Ö–æ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ, "
    "—É–≥—Ä–æ–∑—ã –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å—Å—è –∏–ª–∏ –Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞—Ç—å ‚Äî –≤—ã–±–∏—Ä–∞–π negative, "
    "–¥–∞–∂–µ –µ—Å–ª–∏ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞.\n"
)

logger = logging.getLogger(__name__)


def _auth_headers() -> dict:
    if not YANDEX_API_KEY:
        raise RuntimeError("YANDEX_API_KEY –Ω–µ –∑–∞–¥–∞–Ω")
    return {"Authorization": f"Api-Key {YANDEX_API_KEY}"}


def transcribe_audio_with_speechkit(audio_path: str) -> str:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∞—É–¥–∏–æ—Ñ–∞–π–ª –≤ Yandex SpeechKit –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç.
    –û–∂–∏–¥–∞–µ—Ç—Å—è, —á—Ç–æ –Ω–∞ –≤—Ö–æ–¥ –ø–æ–¥–∞—ë—Ç—Å—è OGG Opus (format=oggopus).
    """

    if not os.path.exists(audio_path):
        raise FileNotFoundError(f"Audio file not found: {audio_path}")

    headers = _auth_headers()
    headers["Content-Type"] = "application/octet-stream"
    if not YANDEX_FOLDER_ID:
        raise RuntimeError("YANDEX_FOLDER_ID –Ω–µ –∑–∞–¥–∞–Ω")

    params = {
        "folderId": YANDEX_FOLDER_ID,
        "lang": YANDEX_SPEECHKIT_LANG,
        "format": YANDEX_SPEECHKIT_FORMAT,
    }

    with open(audio_path, "rb") as f:
        audio_bytes = f.read()

    response = requests.post(
        YANDEX_SPEECHKIT_STT_URL,
        params=params,
        headers=headers,
        data=audio_bytes,
        timeout=30,
    )

    if response.status_code != 200:
        logger.error(
            "SpeechKit error (status=%s): %s",
            response.status_code,
            response.text,
        )
        raise RuntimeError(
            f"SpeechKit STT request failed with status {response.status_code}"
        )

    payload = response.json()
    if payload.get("error_code"):
        raise RuntimeError(
            f"SpeechKit STT error {payload.get('error_code')}:"
            f" {payload.get('error_message')}"
        )

    return (payload.get("result") or "").strip()


def _build_gpt_prompt() -> str:
    """
    –°—Ç—Ä–æ–∏–º –µ–¥–∏–Ω—ã–π –ø—Ä–æ–º–ø—Ç: —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–∞–≤–∏–ª–∞ —Ä–µ—Ä–∞–π—Ç–∞, –∑–∞—Ç–µ–º –ø—Ä–∞–≤–∏–ª–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏,
    –¥–∞–ª—å—à–µ ‚Äî —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –≤–µ—Ä–Ω—É—Ç—å —Å—Ç—Ä–æ–≥–∏–π JSON.
    """
    return (
        f"{NORMALIZATION_PROMPT}\n\n"
        f"{SENTIMENT_PROMPT}\n\n"
        "–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:\n"
        '–í–µ—Ä–Ω–∏ —Å—Ç—Ä–æ–≥–æ –æ–¥–∏–Ω JSON-–æ–±—ä–µ–∫—Ç –±–µ–∑ Markdown, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π –∏ –±–µ–∑ –ª–∏—à–Ω–µ–≥–æ —Ç–µ–∫—Å—Ç–∞:\n'
        '{"normalized_text": "...", "sentiment": "positive|neutral|negative"}\n'
        "–ù–∏–∫–∞–∫–∏—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤, –≤—Å—Ç—É–ø–ª–µ–Ω–∏–π –∏ –ø–æ—è—Å–Ω–µ–Ω–∏–π ‚Äî —Ç–æ–ª—å–∫–æ JSON."
    )


def _heuristic_sentiment_from_text(text: str) -> str:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¢–û–õ–¨–ö–û –ø–æ —Ç–µ–∫—Å—Ç—É, –±–µ–∑ —É—á—ë—Ç–∞ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: 'positive', 'neutral' –∏–ª–∏ 'negative'.
    """
    t = (text or "").lower()

    negative_markers = [
        "–Ω–µ –ø–æ–Ω—Ä–∞–≤",          # "–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å —É—Å–ª—É–≥–∏", "–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å"
        "—É–∂–∞—Å–Ω",              # "—É–∂–∞—Å–Ω—ã–π", "—É–∂–∞—Å–Ω–æ"
        "–æ—Ç–≤—Ä–∞—Ç",             # "–æ—Ç–≤—Ä–∞—Ç–∏—Ç–µ–ª—å–Ω–æ"
        "–∫–æ—à–º–∞—Ä",
        "–ø–ª–æ—Ö–æ–π", "–ø–ª–æ—Ö–∞—è", "–ø–ª–æ—Ö–∏–µ", "–ø–ª–æ—Ö–æ",
        "–º–µ–¥–ª–µ–Ω–Ω",            # "–º–µ–¥–ª–µ–Ω–Ω–æ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ"
        "—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω", "—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∞", "—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏–µ",
        "–Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥",        # "–Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é", "–Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª"
        "–Ω–µ —Å–æ–≤–µ—Ç—É—é",
        "–±–æ–ª—å—à–µ –Ω–µ –ø—Ä–∏–¥—É",
        "–Ω–∏–∫–æ–≥–¥–∞ –±–æ–ª—å—à–µ",
        "–æ–±–º–∞–Ω", "—Ä–∞–∑–≤–æ–¥",
        "—Ö–∞–º—Å—Ç–≤",
        "–Ω–∞–ø–ª–µ–≤–∞—Ç–µ–ª—å—Å–∫",      # "–Ω–∞–ø–ª–µ–≤–∞—Ç–µ–ª—å—Å–∫–∏"
    ]

    positive_markers = [
        # —É–±—Ä–∞–ª–∏ –≥–æ–ª–æ–µ "–ø–æ–Ω—Ä–∞–≤", —á—Ç–æ–±—ã –Ω–µ –ª–æ–≤–∏—Ç—å "–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å"
        "–æ—á–µ–Ω—å –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å",
        "–º–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å",
        "–Ω–∞–º –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å",
        "–ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ",
        "–æ—Ç–ª–∏—á–Ω",
        "–ø—Ä–µ–∫—Ä–∞—Å–Ω",
        "–∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω",
        "—Å—É–ø–µ—Ä",
        "–∫–ª–∞—Å—Å–Ω",
        "—à–∏–∫–∞—Ä–Ω",
        "–¥–æ–≤–æ–ª–µ–Ω", "–¥–æ–≤–æ–ª—å–Ω–∞",
        "–æ—á–µ–Ω—å –¥–æ–≤–æ–ª–µ–Ω", "–æ—á–µ–Ω—å –¥–æ–≤–æ–ª—å–Ω–∞",
        "—Ä–µ–∫–æ–º–µ–Ω–¥—É—é",
        "—Å–æ–≤–µ—Ç—É—é",
        "–±—É–¥—É –æ–±—Ä–∞—â–∞—Ç—å—Å—è –µ—â–µ", "–±—É–¥—É –æ–±—Ä–∞—â–∞—Ç—å—Å—è –µ—â—ë",
        "–±—É–¥—É –ø—Ä–∏—Ö–æ–¥–∏—Ç—å –µ—â–µ", "–±—É–¥—É –ø—Ä–∏—Ö–æ–¥–∏—Ç—å –µ—â—ë",
        "–ª—É—á—à–∞—è", "–ª—É—á—à–∏–π —Å–µ—Ä–≤–∏—Å",
        "—Å–ø–∞—Å–∏–±–æ", "–±–ª–∞–≥–æ–¥–∞—Ä",
        "–≤—Å—ë –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å", "–≤—Å–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å",
    ]

    has_neg = any(marker in t for marker in negative_markers)

    # –µ—Å–ª–∏ —è–≤–Ω—ã–π –Ω–µ–≥–∞—Ç–∏–≤ –µ—Å—Ç—å ‚Äî –æ–Ω –≤–∞–∂–Ω–µ–µ –≤—Å–µ–≥–æ
    if has_neg:
        return "negative"

    has_pos = any(marker in t for marker in positive_markers)

    if has_pos:
        return "positive"

    return "neutral"


def _parse_gpt_response(text: str, fallback: str) -> Tuple[str, str]:
    """
    –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏. –û–∂–∏–¥–∞–µ–º JSON, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π:
    - –≤—ã–¥—ë—Ä–≥–∏–≤–∞–µ–º –ø–µ—Ä–≤—É—é —Ñ–∏–≥—É—Ä–Ω—É—é —Å–∫–æ–±–∫—É {...} –∏–∑ —Ç–µ–∫—Å—Ç–∞;
    - –µ—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º fallback + —Ö—å—é—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π sentiment.
    """
    raw = (text or "").strip()

    try:
        # –ü—ã—Ç–∞–µ–º—Å—è –≤—ã—Ç–∞—â–∏—Ç—å JSON-–æ–±—ä–µ–∫—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞
        match = re.search(r"\{.*\}", raw, flags=re.S)
        json_str = match.group(0) if match else raw

        data = json.loads(json_str)

        normalized = (data.get("normalized_text") or fallback).strip()
        sentiment = (data.get("sentiment") or "").strip().lower()

        if sentiment not in {"positive", "neutral", "negative"}:
            sentiment = _heuristic_sentiment_from_text(normalized)

        return normalized, sentiment

    except Exception as e:
        logger.warning(
            "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å –æ—Ç–≤–µ—Ç YandexGPT –∫–∞–∫ JSON: %r, –æ—à–∏–±–∫–∞: %s",
            raw,
            e,
        )
        normalized = fallback.strip()
        sentiment = _heuristic_sentiment_from_text(normalized)
        return normalized, sentiment


def normalize_and_analyze_with_yandex_gpt(raw_text: str) -> Tuple[str, str]:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –≤ YandexGPT –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ (—Ä–µ—Ä–∞–π—Ç–∞) –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (normalized_text, sentiment).

    - normalized_text: –ø–µ—Ä–µ–ø–∏—Å–∞–Ω–Ω—ã–π –æ—Ç–∑—ã–≤ –±–µ–∑ —Å–ª–æ–≤-–ø–∞—Ä–∞–∑–∏—Ç–æ–≤, —Å –ø—É–Ω–∫—Ç—É–∞—Ü–∏–µ–π;
    - sentiment: 'positive', 'neutral' –∏–ª–∏ 'negative'.
    """
    raw_text = raw_text or ""

    if not YANDEX_FOLDER_ID:
        raise RuntimeError("YANDEX_FOLDER_ID –Ω–µ –∑–∞–¥–∞–Ω")

    headers = {"Content-Type": "application/json"}
    headers.update(_auth_headers())

    model_uri = f"gpt://{YANDEX_FOLDER_ID}/{YANDEX_GPT_MODEL}"

    body = {
        "modelUri": model_uri,
        "completionOptions": {
            "stream": False,
            "temperature": 0.4,  # —á—É—Ç—å —Å–≤–æ–±–æ–¥–Ω–µ–µ, —á—Ç–æ–±—ã —Ä–µ—Ä–∞–π—Ç –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–ª
            "maxTokens": 800,
        },
        "messages": [
            {
                "role": "system",
                "text": _build_gpt_prompt(),
            },
            {
                "role": "user",
                "text": raw_text,
            },
        ],
        # –ü—Ä–æ—Å–∏–º –º–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É—Ç—å –∏–º–µ–Ω–Ω–æ JSON-–æ–±—ä–µ–∫—Ç
        "json_object": True,
    }

    try:
        response = requests.post(
            YANDEX_GPT_URL, headers=headers, json=body, timeout=30
        )
    except requests.RequestException as e:
        logger.error("YandexGPT request error: %s", e)
        normalized = raw_text.strip()
        sentiment = _heuristic_sentiment_from_text(normalized)
        return normalized, sentiment

    if response.status_code != 200:
        logger.error("YandexGPT error (status=%s): %s", response.status_code, response.text)
        normalized = raw_text.strip()
        sentiment = _heuristic_sentiment_from_text(normalized)
        return normalized, sentiment

    payload = response.json()
    try:
        text = payload["result"]["alternatives"][0]["message"]["text"]
    except (KeyError, IndexError) as e:
        logger.warning("–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ YandexGPT: %s (–æ—à–∏–±–∫–∞: %s)", payload, e)
        normalized = raw_text.strip()
        sentiment = _heuristic_sentiment_from_text(normalized)
        return normalized, sentiment

    # –ó–¥–µ—Å—å —É–∂–µ –∏–¥—ë—Ç –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π —Ä–µ—Ä–∞–π—Ç + sentiment –∏–∑ JSON,
    # —Å fallback –Ω–∞ —Ö—å—é—Ä–∏—Å—Ç–∏–∫—É, –µ—Å–ª–∏ JSON –∫—Ä–∏–≤–æ–π.
    normalized, sentiment = _parse_gpt_response(text, raw_text.strip())
    return normalized, sentiment
